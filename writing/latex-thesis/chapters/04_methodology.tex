% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

 \chapter{System Design}\label{chapter:Approach}
 In this chapter we explain the use cases and requirements to design a context-aware pervasive software framework. Then, we illustrate the  proposed architecture and design following from the concepts introduced in the background chapter and taking into account the challenges and possible solutions shown in the foundation chapter. To recap,  our aim is to design a context-aware pervasive software framework to manage and distribute computations while considering resources, dependencies and networking even with an end-to-end path.

\section{Use Cases}
This section provides real life scenarios targeted by our proposed framework. Requirements are then elicited from the use cases and then the framework implementation and design are evaluated against these requirements. Keep in mind that; the framework idea is not just to implement these use cases, but to provide the ability to distribute, compose and execute various use cases for context-aware pervasive computing. The use cases are mainly targeted to help human beings, increasing their life quality and preserve the environment. 

\subsection{Smart Cities}
One of the most researched areas in the field of IoT is making our cities more advanced, connected and helpful to human beings and the environment. Researchers and professionals have had many ideas to make use of the context-aware sensor networks that can communicate and act independently whenever the situation needs intervention. We take some examples of the smart cities application and show how they can be implemented using our software framework.

\subsubsection{Smart lighting}

Smart lighting is a use case for automatic control of outdoor lamp posts hence optimizing costs for the governments and enterprises in addition to helping the environment by saving energy \cite{6740844}. The outdoor lighting can be automatically started or closed according to certain circumstances. For example, by lighting up when motion is detected   around it and turning off when there is no further motion, or by detecting natural light  and weather circumstances. Moreover, the lamp posts can be monitored in order to see when a lamp needs replacement.  Further, lamp posts can detect what is the best lighting percentage in a certain situation according to a machine learning algorithm based on the history of decisions taken and feedback provided by users.\\

\noindent  In order to implement this use case in our proposed software framework, we must be able to distribute a computational flow to all lamp posts using a messaging system.  Also, the flow should be able to access sensors and be capable of adjusting the light according to the input gathered from several sources including motion, light and humidity sensors.  The decisions taken  should  be   stored into a database so that the flow can access  previous decisions in order to asses the current situation. In addition, a flow with an endpoint that  allows users to send feedback on the lighting system can be locally composed to enhance the learning algorithm. Having sent the computational flow to all the lamp posts, the framework should ensure that it does not get deployed on lamp posts without the  required resources, sensors and actuators. 

\subsubsection{Smart Parking}
Automatically detecting empty parking spots in crowded streets is the main idea behind smart parking \cite{4543911}. Since the number of vehicles on the streets are in tremendous increase \cite{cars}, the urge for finding a parking spot in city centers and crowded places has also increased. Having a smart parking mechanism helps in wasting less time, decreasing energy consumption and maintaining a clean environment by reducing emissions.  Different information sources can be used to  detect empty parking spots, for instance, image and video footage of street cameras, crowd sourcing of information and APIs for parking services. Implementing this use case has almost similar requirements to smart lighting, however, it adds having  a camera integrated with smart devices which might produce the need for streaming the footage in real-time to other devices.


%\subsubsection{Crowded Subway Cars detection}
%Using the subway as a mean of transportation in the rush hour can be troublesome, most subway cars are crowded in that time. However, in some of the cases, people in the cars are not normally distributed meaning some cars may be less or more crowded than the others. In this sense, people %thought of using cameras, sensors and actuators to signal people for the less crowded cars. 



\subsection{Mining Applications}

In underground mines it is necessary to always monitor gas and temperature levels in order to prevent miners suffocation \cite{doi:10.1155/2013/159273}. At the same time, it is very hard to maintain a connection between sensors in the inside and  monitoring systems outside \cite{ginzboorg2010dtn}. Therefore, the devices incorporated with sensors inside the fields are expected to be pervasive and warn miners from unexpected increase of gas levels on their own. In addition to delivering the data to the outside world, the system must be able to gather data about the situation inside. This requires miners to act as middlemen who store delay-tolerant data into their mobile devices and carry it forward to the outside world. Of course the miners cannot do this process manually, therefore, there should be a messaging system on their mobile devices that carry the data and handle the synchronization with other device. Also, carrying the data in and out is not the only issue, importing and visualizing  data in the monitoring system should be also done automatically.\\

\noindent The mining use case is a delay-tolerant application because there is a big chance there are no wiring going in and out of the mine where new tunnels are constructed thus a delay-tolerant messaging system should be used. But also, it is an information-centric  application because data should be sent  from  devices in the mine to be imported in  the monitoring system without knowing their host names. Having smart devices installed in the mine means it is very hard to target them as endpoints without a valid connection, even if there was one, knowing the host names of these devices might still be an issue. Same applies to the monitoring system outside,  data cannot be sent to a specific host name, rather sent to whoever is interested in  these data.

\subsection{Privacy and Security}
The surveillance systems used at the moment uses closed-circuit television cameras to send  tapes, images and footage of people using public transportation to  storage systems \cite{Ashby2017} . The police could acquire  these tapes in case of incidents  to  observe, monitor and  apply facial recognition algorithms in order to  detect faces of wanted criminals  to prevent crimes and anti-social behavior \cite{cctv}. Despite this being of  significant importance to the national security, this puts everyones privacy in jeopardy. Therefore, we thought of replacing this model by a pervasive one, where  the facial detection algorithm and faces of  wanted criminals are pushed to the smart devices in public transportation means and whenever a match is found the national security is notified. This could also be  triggered only whenever there is an incident using computer vision, which helps greatly in increasing privacy, decreasing  latency between the footage and detection in addition to minimizing network bandwidth since the streaming footage  will not be uploaded to the cloud unless there is a match. Similar approaches were introduced in \cite{4653063} and \cite{winkler2010trustcam} where the footage is analyzed on spot to protect privacy. Nevertheless, this is not trivial, facial recognition algorithms are complex and depends on other libraries and  detection models. Therefore, the computation which includes the recognition algorithm  must be able to carry dependencies otherwise the computation will not run. Moreover, the national security should be able to update the list of criminal faces thus messages sent to the smart devices should allow also attachments and dependencies as well. 


\section{Requirements} \label{sec:requirements}

What follows is a listing of  the requirements extracted from the real life use cases mentioned in the previous section. We then  evaluate the design and implementation of the framework according to the derived requirements which are  classified  in the following points:
%The framework should
\begin{enumerate}
\item \textit{Service discovery}: since we do not know the host names of the smart devices nor their addresses, the framework should have service discovery mechanism encapsulated in the messaging system as explained in Section \ref{subsec:pub-sub}  to discover peers and  allow any interaction between smart devices.
		
\item \textit{Send and deploy computations}: whatever the use case may be, one of the main requirements of this work, is to be able to send computations to smart devices. This includes sending to one, a set or all smart devices connected together in a network. However, to deploy a computation, the receiving side must have the required hardware resources, sensors and actuators to be qualified for deploying the computation.
 
 \item \textit{Computation dependencies}: complex computations which cannot be executed using the basic operating system and common libraries installed on the smart devices, should carry their  own custom dependencies in order to guarantee a successful run on the receiving smart devices. 


\item \textit{Disconnected devices}: since the framework is also designed to be used in challenged networks, isolated devices in separate networks should also send and receive data or computations using the delay-tolerant architecture.


\item \textit{Communication}: smart devices should be able to communicate, send and receive data in an information-centric and a publish-subscribe manner.

\item \textit{Global identifier}: each smart device must have its own unique global identifier which can be used to send data and computations to this device only.

\item \textit{Composability}: the framework should allow composition of multiple computations either locally through a database or globally by allowing data exchange via the publish-subscribe messaging system.

\item \textit{Pervasiveness}: each computation should be able to act on its own, trigger actuators, persist data and access resources such as cameras and sensors if required by the use case.
\end{enumerate}

\section{Framework Stack}\label{sec:design}
This section explains the software framework architecture designed for pervasive environments and challenged networks to distribute and manage computations with their respective resources and dependencies.  The main idea behind this design is to harness the features of node-RED to create, deploy and share computations of any kind. In addition to having SCAMPI as an information-centric, publish-subscribe and delay tolerant messaging system that gives the framework the ability to deliver messages even without an end-to-end path. However, node-RED and SCAMPI are two different environments that cannot manage computations, resources and dependencies on their own. They need a middleware to orchestrate the communication between them.\\


\noindent In general the architecture stack on each device should look like Figure \ref{fig:stack}. With SCAMPI at the stack bottom relying only on the JVM. Then on top of SCAMPI is its Java API to communicate with the TCP API of SCAMPI. Afterwards, comes the middleware which acts mediator in between node-RED and SCAMPI. Finally, at the very top exits node-RED to run computations and interact with the user if needed. However, if SCAMPI is used on an android device, there might be no need to run neither the middleware nor node-RED since the phone will be  merely used to transport data from one device to another having no end-to-end path. Below we explain how each component of the system works.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{images/stack.png}
	\caption{The framework architecture stack.  }
	\label{fig:stack}
\end{figure}



\subsection{SCAMPI}
As mentioned before SCAMPI is an information-centric, publish-subscribe and delay-tolerant messaging system. In this framework we use SCAMPI to send or receive messages that include computations and data. SCAMPI is also broker-less meaning we do not have to set up a server as broker which is one of the main reasons we chose SCAMPI, in order to be dynamic as possible. The other main reason is to reach devices which do not have direct connectivity to the publishing device or do not have end-to-end path. \\

\noindent Being a delay-tolerant networking architecture, SCAMPI can use its store-carry-forward routing to deliver messages in challenged environments. In figure \ref{fig:scampi-design}, we show how SCAMPI uses mobile phones to connect devices that do not have a route or  direct connection and want to exchange messages. In the figure, there are three Raspberry Pi devices running our proposed stack. The first two  have network connection therefore it is rather easy to exchange messages between themselves. However, the third one is isolated, nevertheless it can be connected to a Wi-Fi network or run as an access point. In this case, an android device passing  between network \textit{N1} and \textit{N2} can carry the message bundles from one network and forward it to the other by connecting to both networks alternatingly.  Thus, reaching out to challenged environments that cannot be reached using wired or wireless connections.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{images/scampi.png}
	\caption{SCAMPI synchronization even without an end-to-end path. }
	\label{fig:scampi-design}
\end{figure}

\noindent Being information-centric, data-centric with publish-subscribe pattern and having peer discovery helps us in achieving our dynamic framework without knowing any host names. It  also supports adding and removing devices at will without any additional configuration. We can also use the general identifiers of the devices as topics in order to target each of them independently. As stated, SCAMPI does not have any dependencies other than the JVM so we just run it on each device and we are  good to go. \\


\noindent The SCAMPI Java API acts as a client to the server allowing us to publish or subscribe for any topic from the Java environment. Therefore, we are able to extend this API and create a running Java application that uses the TCP API for SCAMPI underneath. The API also allows the client to override the functions for SCAMPI status changes  for instance if it is disconnected, stopped or most importantly when a new message is received. Furthermore, there is a model called \textit{SCAMPIMessage} used to create messages, it assists in assigning attributes to the message whether strings, integers or even binaries. Also, one can assign meta-data and lifetime to the message.


\subsection{Node-RED}

Node-RED is a tool used for wiring IoT applications, its flows describe the intended computations. It has exporting and importing endpoints for flows via REST which makes it easy to deploy without human interaction.  Flows can be also configured to access certain tables or collections on a running database instance and this configuration can be serialized with the flow. In this framework whenever a flow wants to send a message to another flow on the same node-RED instance or on other instances, it either uses the REST API that the middleware provides to publish and subscribe to data topics or the same database configuration in both flows to be able to communicate data through the database. This allows node-RED to send or receive data and allow composability both locally and globally.  Further, node-RED is rich with predefined nodes that  can be used to run flows on time intervals, connect to emails, twitter accounts or even access a gpio pin on Raspberry Pi. Node-RED usage is intuitive since it is based on flow-programming, it does not need a developer to create a flow.

\subsection{Maestro}
Maestro  is this framework's middleware and the main contribution of this work, it is deployed along with node-RED and SCAMPI on each instance in this architecture. It runs a jar file containing a web application server. It has several duties in orchestrating  SCAMPI messages to node-RED instances.
\begin{itemize}
\item It reads the machine specifications to initialize the machine's resources, sensors and actuators 	.
\item It includes the SCAMPI Java API and has a REST API over it which allows any other script from any other language ("including node-RED") to use the publish-subscribe feature of SCAMPI.
\item Maestro subscribes by default to the computation topic in order to  send and receive computations.
\item Maestro subscribes to the unique global identifier of SCAMPI at the framework initialization to act as an identifier for the whole stack.

\item It analyzes  flows by checking the meta-data  attached to the message thus if Maestro finds out that a device does not have the necessary hardware requirements, sensors or actuators, it will not deploy the flow. 
\item It is responsible for attaching dependencies of  node-RED flows when one is published, also for putting them into the correct directory when receiving them.
\item It provides a message caching mechanism in order to make sure messages are not handled more than once.
\item it provides a mapping between the topics and node-RED flows meaning if one or more flows are interested in the same topic, all of them should get the data exchanged on this topic.
 \end{itemize}

\section{Framework Architecture} \label{sec:arhcitecture}
What follows is an explanation of the framework design and architecture and how it can be used to achieve the goals of this thesis. We describe a step by step guide to design and distribute a flow that portrays a pervasive use case.


\subsection{Physical Components}
Before we get into the software components and how we can use the framework stack to implement a pervasive use case, we first show the physical components that are used by our framework. There are three main devices used in this architecture:
\begin{itemize}
\item \textit{Raspberry Pi}: we use the Pi as a low-cost single board computer that contains gpio pins which can be connected to sensors and actuators.  However, the Pi can be replaced by any single board computer that runs an operating system supporting the JVM and can host node-RED as an execution environment. Each Pi in this framework has our stack installed in addition to a camera,  an RGB LED, a temperature and a motion sensor as shown in Figure \ref{fig:node}. All the Raspberry Pis in our design have the sensors connected to the same gpio pins, for instance, all the temperature sensors are connected to gpio pin 11 on each  Raspberry Pi. This is important because when we send the computation script for sensing temperatures to all the Raspberry Pis, the script will be accessing the same pin to get a hold of the sensor data. \\



\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{images/node.png}
	\caption{A Raspberry Pi in our architecture connected to sensors and running our stack. }
	\label{fig:node}
\end{figure}

\noindent Now recalling the issue described in Section \ref{subsec:sensors-and-actuators}, which explained that multiple flows might attempt to access a resource at the same time (temperature sensor for example). If we sent another computation which also tries to access the same resource, it will fail with a high probability. Since a resource can only be accessed by one computation at a time. Therefore, we have only flow that access the resource and stores data into a database and then other computations can query the data from the database.

\item \textit{Intel NUC}: we use the NUC as a computer with high performance capabilities compared  to the Raspberry Pi. NUC devices in the architecture also run our stack and  are used to prove that we can delegate the computations requiring high performance from the Raspberry Pis to high performing devices. It is not connected to any sensors or actuators. The NUC can be replaced as well with any high computing device with an operating system supporting the JVM  and capable of hosting node-RED. 

\item\textit{Android Phone:} in order to confirm that we can deliver computations and data to challenged networks, we used an android phone running SCAMPI so that we can carry data from one network to another. The phone runs only SCAMPI and not whole stack, however, node-RED supports android devices while Maestro also only relies on the JVM therefore we can deploy the whole stack if we have a use case for executing computations on android phones.

\end{itemize}

\noindent Figure \ref{fig:components} shows one possibility to connect the devices in our architecture where we have two Raspberry Pi's connected together with an Intel NUC in a network, and another Raspberry Pi in a separate one that communicates with the other devices using the Android device  switches between both networks.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{images/components.png}
	\caption{Physical components of the architecture. }
	\label{fig:components}
\end{figure}


\subsection{Designing a Flow}
The first step to distribute a pervasive use case in a network is to design the computation which implements the use case, and since we use node-RED to design and execute flows, therefore the first step is to use node-RED to create a flow by wiring and connecting nodes. Each existing node in node-RED has a different functionality, also additional nodes developed by other contributers can be installed into the local instance. If a specific functionality can not be found  in the existing nodes or the ones available from the contributors, the functionality can be implemented using any programming language and then  the \verb|exec| node available in node-RED can be used to access the scripts in node-RED directory and run it. Moreover, the  existing \verb|function| node can be used to implement the functionality using  JavaScript. \\

\noindent Triggering flows is very important as explained in \ref{sec:foundation}, there are multiple options to trigger flows. The first one is using the \verb|inject| node which allows  triggering the flows in multiple ways such as every time interval, once a flow is deployed, between time intervals or at specific time. The second way to trigger computations is via receiving a request using a \verb|http request| node on a specific endpoint that is wired to the flow just as Maestro does to deliver data to node-RED flows. There are also other ways that could be devised according to the desired use case.\\
 

\noindent Accessing sensors and actuators can be done in several ways using node-RED. The first way is to use the existing gpio nodes which can access the Raspberry Pi pins to read  and give digital signals to the sensors and actuators. However, we found out that the existing gpio nodes are not stable, therefore, we used the second option to access sensors and actuators using python scripts that are executed using the \verb|exec| nodes. The python scripts are then transfered with the computation as  dependencies.\\

\noindent There are also different  database nodes that can be installed on the local node-RED instance, for example, \textit{InfluxDB} the time-series database and \textit{MongoDB}. Each supports writing and querying data from the local database instance. When a flow is configured to have a database configuration, the user can specify whether it should live across all node-RED flows or can  only be used by a specific flow.  Yet when we chose to have the database configuration across all node-RED flows, the configuration was not serialized along with each flow. Thus, it is advised to configure the flows in a way that each has its own configuration so that it can be serialized along with the flow and can reach other devices in the network.\\


\subsection{Sending the Flow to Heterogeneous Devices}


\noindent Having designed a flow representing a use case, we can send the flow along with its dependencies to devices in the network while accounting for their available sensors, actuators  and hardware resources. To achieve this, we developed a node-RED flow with  a user interface that can be used by the framework to send other flows to the devices running our stack. As shown in Figure \ref{fig:html-publish}, once we have designed a flow and have the flow identifier, we can adjust the computation power and the required free random access memory for each specific flow we publish. In addition to selecting the required sensors and actuators to cater for the heterogeneous devices and their sensors availability. Further, the scripts used by the \verb|exec| nodes inside the flow can be selected in the HTML page as dependencies. Once we set everything regarding the flow meta-data and we click on the \verb|push| button, a request is sent to Maestro in order to handle sending the computations and meta-data to SCAMPI and other devices.
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/html-publish.png}
\caption{The HTML page used to publish computations.}
\label{fig:html-publish}
\end{figure}

\noindent When Maestro receives the computational flow  together with the meta-data and dependencies from  node-RED. It creates a new SCAMPIMessage with  a global unique identifier, then it puts the  file references for the dependencies used by the computation as a binary parameters in the message. Finally, it publishes the message on a specific topic to SCAMPI and returns a success response to node-RED. After SCAMPI receives the message from Maestro, it publishes the message to all discovered peers. It also keeps a copy in the cache in case it discovers new devices. 


\subsection{Receiving the Flow}
Since Maestro subscribes  by default  to the topic of exchanging computational flows, whenever SCAMPI on the receiving devices gets a new message it  is forwarded to Maestro. Afterwards, Maestro checks the hardware resources, sensors and actuators of the computation and compares it with the machine specification. Then Maestro puts the dependencies carried by the SCAMPI message to node-RED directory before deploying the computation to node-RED.  \\


\noindent As described in \ref{subsec:ddf}, $S(t)$ is a set that contains all devices in a system. From this set, we can have a subset $S_c(t)$ which is the candidate set that satisfies the requirements for a certain computation.  Applying this to our design and as shown in Figure \ref{fig:sets}, if we publish a computation that needs low computing  power, motion and temperature sensors to a network of devices. The flow should only be deployed by those who fulfill requirements only. In the figure, neither the Intel NUC nor the Raspberry Pi without the required sensors were able to deploy the computation. Further, in the current Maestro implementation, if it receives a computation and  the requirements  are not met, then the computations are discarded completely. There is a possibility to queue the  messages which failed the hardware requirements, such as low random access memory or high CPU usage of the current device, in order to be deployed again when the resources are freed.  However, as explained in Section \ref{subsec:resources}, this introduces a scheduling problem, after the resources are freed, queued computations will compete for the free resources.






\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{images/sets.png}
	\caption{Deploying computations to heterogeneous devices.}
	\label{fig:sets}
\end{figure}



\section{Sending and Receiving Data}

We explain how the stack can send and receive data using our framework architecture in the following points:
\begin{itemize}
\item As discussed in Section \ref{subsec:io-spec}, the flows should send and receive data using the messaging system described in Section \ref{subsec:pub-sub} in order to achieve global composability. By using our framework, we can communicate data on a any topic except the computation topic. This is done  by using a \verb|http request| node that uses Maestro REST API to publish and subscribe to data on a specific topic.\\

\item Local composability discussed in  \ref{subsec:io-spec}, can also be achieved by sending two flows with the same database configuration which get serialized along with the computational flows to other devices. Each one of them can read or write to the same database instance. Moreover, since collections in time-series databases do not need a schema we can insert  data of any form immediately. 

\item On the sender side, on the one hand, when Maestro receives a new publish request, it creates a new SCAMPIMessage with a unique global identifier and publishes it to SCAMPI which handles delivering the message to other devices. On the other hand, for each flow that subscribes to a specific data topic to Maestro, it  adds an entry in the topic-endpoint mapping that maps between a topic and an endpoint identifying the flow. On the receiving side, when Maestro gets a message from SCAMPI because it had subscribed for a specific topic. Maestro forwards the data to all endpoints on node-RED that had previously subscribed to this topic, this enables the flexibility of having multiple flows subscribing to the same data.\\


\item When  publishing a data message, the publisher can attach a parameter that indicates whether the response of this message should be sent to the publisher only, or sent to specific topic that might have multiple subscribers. This helps publishers in sending data to be processed on other devices and then control who should receive the processing results.\\


\item Since Maestro subscribes to the global identifier of SCAMPI and thus the framework, it is possible to publish flows or data to specific nodes or set of nodes as discussed in \ref{subsec:ddf} by  publishing the message once for each device. However if the set is too big, this might flood the network with the same message published to different topics for various devices. More optimized solutions could be achieved by exposing the information to the routing algorithm of SCAMPI thus being able to publish the message only once as explained in \ref{subsec:resources}. \\



\end{itemize}
\subsection{Architecture Summary}

As a recap, the following Figure \ref{fig:design} summarizes how the framework works and shows how flows are distributed and data is exchanged between the stack components. 
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{images/design.png}
	\caption{Software framework architecture design. }
	\label{fig:design}
\end{figure}

\begin{enumerate}[label=(\Alph*)]
 
 \item Flows are developed using node-RED UI, they can include publishing and subscribing REST calls to Maestro. If a flow subscribes to a certain topic, Maestro creates  a topic-endpoint mapping between the topic and an endpoint for this flow specifically, then send a subscribe request to SCAMPI. If another flow on the same instance wants to subscribe to the same topic, Maestro extends the mapping to include it, hence, once a message is received it gets forwarded to all subscribed flow endpoints. 

 \item When Maestro receives a publish request from node-RED, it attaches the dependencies and an indicator that states if the response should be received by the sending device only. Then the message is forwarded to SCAMPI server.

 \item SCAMPI keeps synchronizing messages and discovering new peers continuously as long as its running. Also, storing some message for the store-carry-forward routing functionality.

 \item When a SCAMPI instance receives a message it is forwarded to Maestro, which then verifies the topic. If it was a computation message then Maestro checks meta-data, resources, dependencies and then either deploy the computation to node-RED or discard it. Otherwise, if the message was not a computation, Maestro forwards it to the subscribing flows from the topic-endpoint mapping. 

\end{enumerate}

\section{Summary}

In this chapter we introduced real life use cases for our software framework that was utilized to elicit the requirements used to evaluate the implementation and design of this framework. Afterwards, we described the stack  to implement this framework starting by SCAMPI the  delay-tolerant information-centric messaging system, going through node-RED the platform used to implement, export and execute custom computations serving different use cases, finally we explained Maestro which is the middleware that orchestrates the communication between SCAMPI and node-RED. Then we explained how the whole framework is expected to operate  fulfilling  the thesis goals.